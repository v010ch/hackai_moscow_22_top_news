{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40e726ae-286d-4aba-85b1-13af34c9eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8bf4b97-938d-404c-ad75-f1938fde2f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2022-07-23T19:11:42.028393+03:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.7.10\n",
      "IPython version      : 7.22.0\n",
      "\n",
      "Compiler    : MSC v.1916 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 158 Stepping 9, GenuineIntel\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "073bff5c-f88a-46b4-b122-81b2c1f01fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "notebookstart= time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "007c22c0-885c-48e7-9e16-43536efe0980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "import category_encoders as ce\n",
    "from sklearn import preprocessing\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ace0e36d-2f5f-42e2-b4a0-b7eeb58f0ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_encoders: 2.2.2\n",
      "sklearn          : 0.24.2\n",
      "pandas           : 0.25.3\n",
      "numpy            : 1.20.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daf7006-0f02-48cc-a9be-aec5b3df5b89",
   "metadata": {},
   "source": [
    "## Reproducibility block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d715fcc1-cd77-4e37-bf03-7d6c62ac3c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed the RNG for all devices (both CPU and CUDA)\n",
    "#torch.manual_seed(1984)\n",
    "\n",
    "#Disabling the benchmarking feature causes cuDNN to deterministically select an algorithm, \n",
    "#possibly at the cost of reduced performance.\n",
    "#torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# for custom operators,\n",
    "import random\n",
    "random.seed(5986721)\n",
    "\n",
    "# \n",
    "np.random.seed(62185)\n",
    "\n",
    "#sklearn take seed from a line abowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda75999-7bd7-47f8-b4fd-6aac0562dde5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10c73d28-8eba-403c-9eb4-6cee5e76a593",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_DATA  = os.path.join(os.getcwd(), 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f17b407-3c2a-4044-8e71-f3819e0068c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctr для специальных статей по украине\n",
    "CTR_UKR = 6.096"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfee7f1b-6bf8-4e1b-8025-877ce98641b4",
   "metadata": {},
   "source": [
    "энкодеры для кодирования категориальных переменных. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb8f47d-1028-4b27-a094-01ef85da8601",
   "metadata": {},
   "source": [
    "но, например, для catboost не требуется такого кодирования, так что оригинальный признак так же останется в датасете,   \n",
    "а в модель будут передоваться признаки только через параметр features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bc7a45-d159-4127-8ad7-a5e40e0cc3dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "324446e1-7bcb-4ad6-accc-6dc5eacb921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(DIR_DATA, 'train_extended.csv'))#, index_col= 0)\n",
    "df_test  = pd.read_csv(os.path.join(DIR_DATA, 'test_extended.csv'))#, index_col= 0)\n",
    "\n",
    "df_train['publish_date'] = pd.to_datetime(df_train['publish_date'])\n",
    "df_test['publish_date']  = pd.to_datetime(df_test['publish_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bee87a3c-d9dc-48c2-a4ce-c724785c9b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 17), (3000, 14))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d639e436-931d-4b14-9463-4197aab035b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4dce281-329d-4605-a690-0b184a9bb3d7",
   "metadata": {},
   "source": [
    "Имена признаков для удобства перебора будут представлены словарем   \n",
    "Формат:   \n",
    "{\n",
    "исходный признак/идея: {   \n",
    "только числовые признаки: [ ]   \n",
    "только категориальные признаки: [ ]   \n",
    "признаки, которые могу быть как числовыми так и категориальными: [ ]   \n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d323b9e5-02b2-4b6d-8f6c-0f10271673f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clmns = {'document_id':{'num':  ['nimgs','text_len', ],   \n",
    "                        'cat':  [],\n",
    "                        'both': [],\n",
    "                        },\n",
    "        'title':         {'num':  [],   \n",
    "                          'cat':  [],\n",
    "                          'both': [],\n",
    "                         }, \n",
    "        'publish_date': {'num':  [],   \n",
    "                          'cat':  [],\n",
    "                          'both': [],\n",
    "                         },\n",
    "         'authors': {'num':  [],   \n",
    "                     'cat':  [],\n",
    "                     'both': [],\n",
    "                    },\n",
    "         'ctr': {'num':  [],   \n",
    "                 'cat':  [],\n",
    "                 'both': [],\n",
    "                },\n",
    "         'category': {'num':  [],   \n",
    "                      'cat':  [],\n",
    "                      'both': [],\n",
    "                     },\n",
    "         'title': {'num':  [],   \n",
    "                   'cat':  ['two_articles'],\n",
    "                   'both': [],\n",
    "                },\n",
    "        'tags':{'num':  [],   \n",
    "                'cat':  [],\n",
    "                'both': [],\n",
    "                },\n",
    "         'poly':{'num':  [],   \n",
    "                'cat':  [],\n",
    "                'both': [],\n",
    "                },\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7296b2a6-5d3e-420e-91b0-d4d14f08a1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['document_id' 'title' 'publish_date' 'session' 'authors' 'ctr' 'category'\n",
      " 'tags' 'views' 'depth' 'full_reads_percent' 'true_category' 'true_title'\n",
      " 'nimgs' 'overview' 'text_len' 'two_articles']\n"
     ]
    }
   ],
   "source": [
    "print(df_train.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb1a2b7-e60f-492e-9aa6-cf1456582820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2967f281-1164-43df-9678-146877565bc8",
   "metadata": {},
   "source": [
    "## Очистка датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5034fc71-4fd8-4ebd-8bbf-6457485f4c1a",
   "metadata": {},
   "source": [
    "этих категорий нет в тесте, а в трейне на них приходится всего 3 записи. они явно лишние.\n",
    "\n",
    "уберем статьи раньше минимальной даты в тесте. для начала так, дальше можно будет поиграться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a683054c-62c3-4f7e-b179-698648c862f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_data(inp_df: pd.DataFrame, min_time: pd.Timestamp) -> pd.DataFrame:\n",
    "    \n",
    "    exclude_category = {'5e54e2089a7947f63a801742', '552e430f9a79475dd957f8b3', '5e54e22a9a7947f560081ea2' }\n",
    "    inp_df = inp_df.query('category not in @exclude_category')\n",
    "    print(f'shape after clean category {inp_df.shape}')\n",
    "    \n",
    "    inp_df = inp_df[inp_df.publish_date >= min_time]\n",
    "    print(f'shape after min time {inp_df.shape}')\n",
    "    \n",
    "    inp_df = inp_df.query('ctr != 6.096')\n",
    "    print(f'shape after ctr {inp_df.shape}')\n",
    "    \n",
    "    if 'full_reads_percent' in inp_df.columns:\n",
    "        inp_df = inp_df.query('full_reads_percent < 100')\n",
    "        print(f'shape after frp time {inp_df.shape}')\n",
    "    \n",
    "    return inp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a62e0fbf-896e-4a49-9d83-77d614e0d9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape after clean category (6997, 17)\n",
      "shape after min time (6989, 17)\n",
      "shape after ctr (6983, 17)\n",
      "shape after frp time (6981, 17)\n"
     ]
    }
   ],
   "source": [
    "min_test_time = pd.Timestamp('2022-01-01')\n",
    "\n",
    "df_train = clear_data(df_train, min_test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b68554b-710a-4295-bf63-0e980a29ac48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1608271f-2677-49a1-8a01-e48b0d21e127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8e24525-69a0-440e-8104-11968190153f",
   "metadata": {},
   "source": [
    "## title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b29e57b-b7ca-4fb1-870f-84e55a0147f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_title_features(inp_df):\n",
    "    \n",
    "    # Прямая трансляция, Фоторепортаж, Фотогалерея, Видео, телеканале РБК, Инфографика endswith\n",
    "    \n",
    "    inp_df['ph_report']  = inp_df.true_title.apply(lambda x: 1 if x.endswith('Фоторепортаж') else 0)\n",
    "    inp_df['ph_gallery'] = inp_df.true_title.apply(lambda x: 1 if x.endswith('Фотогалерея') else 0)\n",
    "    inp_df['tv_prog'] = inp_df.true_title.apply(lambda x: 1 if x.endswith('телеканале РБК') else 0)\n",
    "    inp_df['online'] = inp_df.true_title.apply(lambda x: 1 if x.endswith('Прямая трансляция') else 0)\n",
    "    inp_df['video']  = inp_df.true_title.apply(lambda x: 1 if x.endswith('Видео') else 0)\n",
    "    inp_df['infogr'] = inp_df.true_title.apply(lambda x: 1 if x.endswith('Инфографика') else 0)\n",
    "    \n",
    "    inp_df.overview.fillna('', inplace = True)\n",
    "    inp_df['interview'] = inp_df.overview.apply(lambda x: 1 if 'интервью РБК' in x else 0)\n",
    "    \n",
    "    \n",
    "    if 'video' not in clmns['title']['both']:\n",
    "        clmns['title']['both'].extend(['ph_report', 'ph_gallery', 'tv_prog', 'online', 'video', 'infogr', 'interview'])\n",
    "        \n",
    "    return inp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17421333-8c5c-485b-a2a0-520ff87c04d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = add_title_features(df_train)\n",
    "df_test = add_title_features(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3295307-8b66-4ed6-ac80-b92b824e1875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 12, 11, 1, 44, 31)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.ph_report.sum(), df_train.ph_gallery.sum(), df_train.tv_prog.sum(), df_train.online.sum(), df_train.video.sum(), df_train.infogr.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd7d11b4-8d2b-4ddc-8517-d6a834b98754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 4, 2, 1, 16, 14)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.ph_report.sum(), df_test.ph_gallery.sum(), df_test.tv_prog.sum(), df_test.online.sum(), df_test.video.sum(), df_test.infogr.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9a6781-08fa-426f-a047-a2ae0e9d3285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1933e1c3-9c41-468b-8d00-7dd609b686ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb06ffe3-8091-4a64-9651-42a41feb2dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01339141-460b-4320-b667-d3f7ca8587f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44194072-b43d-4aa1-9636-f2d367c58dfd",
   "metadata": {},
   "source": [
    "# publish date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdcd2325-4015-44d6-89b9-5966b3810cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = {pd.Timestamp('2022-01-01').date(), pd.Timestamp('2022-01-02').date(), pd.Timestamp('2022-01-03').date(),\n",
    "            pd.Timestamp('2022-01-04').date(), pd.Timestamp('2022-01-05').date(), pd.Timestamp('2022-01-06').date(),  #NY\n",
    "            pd.Timestamp('2022-01-07').date(), pd.Timestamp('2022-01-08').date(), pd.Timestamp('2022-01-08').date(),\n",
    "            pd.Timestamp('2022-02-23').date(), # 23 feb\n",
    "            pd.Timestamp('2022-03-06').date(), pd.Timestamp('2022-03-07').date(), pd.Timestamp('2022-03-08').date(), # 8 march\n",
    "            pd.Timestamp('2022-05-02').date(), pd.Timestamp('2022-05-03').date(), # 1st may\n",
    "            pd.Timestamp('2022-05-09').date(), pd.Timestamp('2022-05-10').date(),# 9 may\n",
    "            pd.Timestamp('2022-06-12').date(), pd.Timestamp('2022-06-13').date(), # day of the russia\n",
    "            pd.Timestamp('2022-11-04').date()\n",
    "           }\n",
    "\n",
    "day_before_holiday = {pd.Timestamp('2021-12-31').date(), pd.Timestamp('2022-02-22').date(), pd.Timestamp('2022-03-05').date(),\n",
    "                      pd.Timestamp('2022-02-23').date(),\n",
    "                      pd.Timestamp('2022-04-29').date(), pd.Timestamp('2022-05-04').date(), \n",
    "                      pd.Timestamp('2022-05-05').date(), pd.Timestamp('2022-05-06').date(),\n",
    "                      pd.Timestamp('2022-11-03').date(),\n",
    "                      #pd.Timestamp('2022-12-03').date(),\n",
    "                      #pd.Timestamp('2022-11-03').date(),\n",
    "                     }\n",
    "day_after_holiday = {pd.Timestamp('2022-01-10').date(), pd.Timestamp('2022-02-24').date(), pd.Timestamp('2022-03-09').date(), \n",
    "                     pd.Timestamp('2022-06-14').date(), pd.Timestamp('2022-05-11').date(),\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87caf595-84c5-4a9a-9958-34fead719a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "border = pd.Timestamp('2022-04-08').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "492f5441-4158-4144-b546-863669e594ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def publish_date_features(inp_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    inp_df['m_d'] = inp_df['publish_date'].dt.date\n",
    "\n",
    "    inp_df['hour'] = inp_df['publish_date'].dt.hour\n",
    "    \n",
    "    inp_df['hour_peak'] = inp_df.hour.apply(lambda x: 1 if x in [4, 12, 16, 21] else 0)\n",
    "    \n",
    "    inp_df['dow']  = inp_df['publish_date'].dt.dayofweek\n",
    "    inp_df['day']    = pd.to_datetime(inp_df['publish_date']).dt.strftime(\"%d\").astype(int)\n",
    "    inp_df['mounth'] = pd.to_datetime(inp_df['publish_date']).dt.strftime(\"%m\").astype(int)\n",
    "    \n",
    "    \n",
    "    inp_df['holiday'] = inp_df.m_d.apply(lambda x: 1 if x in holidays else 0)\n",
    "    inp_df['day_before_holiday'] = inp_df.m_d.apply(lambda x: 1 if x in day_before_holiday else 0)\n",
    "    inp_df['day_after_holiday'] = inp_df.m_d.apply(lambda x: 1 if x in day_after_holiday else 0)\n",
    "    \n",
    "    inp_df['distrib_brdr'] = inp_df.m_d.apply(lambda x: 1 if x < border else 0)\n",
    "    \n",
    "    \n",
    "    if 'hour' not in clmns['publish_date']['both']:\n",
    "        clmns['publish_date']['both'].extend(['hour', 'dow', 'day', 'mounth', 'hour_peak'])#, 'distrib_brdr'])\n",
    "        \n",
    "    if 'holiday' not in clmns['publish_date']['both']:\n",
    "        clmns['publish_date']['both'].extend(['holiday', 'day_before_holiday', 'day_after_holiday', 'distrib_brdr']) \n",
    "    \n",
    "    return inp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72ccf6f7-36b0-486c-abae-ef1ccf57d58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before  (6981, 24) (3000, 21)\n",
      "after   (6981, 34) (3000, 31)\n"
     ]
    }
   ],
   "source": [
    "print('before ', df_train.shape, df_test.shape)\n",
    "df_train = publish_date_features(df_train)\n",
    "df_test  = publish_date_features(df_test)\n",
    "print('after  ', df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1adc733f-d392-4e10-807d-c36ec079d2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223 402 78\n",
      "80 142 29\n"
     ]
    }
   ],
   "source": [
    "print(sum(df_train.holiday), sum(df_train.day_before_holiday), sum(df_train.day_after_holiday), )\n",
    "print(sum(df_test.holiday), sum(df_test.day_before_holiday), sum(df_test.day_after_holiday), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e4694a-019d-4563-b50e-7fd467e617d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc2953a8-8543-49af-984e-b8110491b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_cols = ['hour',\n",
    "             'hour_views_min', 'hour_views_max', 'hour_views_mean', 'hour_views_std',\n",
    "             'hour_depth_min', 'hour_depth_max', 'hour_depth_mean', 'hour_depth_std',\n",
    "             'hour_frp_min', 'hour_frp_max', 'hour_frp_mean', 'hour_frp_std',\n",
    "            ]\n",
    "hour_stats_start = df_train[df_train.distrib_brdr == 1].groupby(['hour'])[['views', 'depth', 'full_reads_percent']].agg(['min', 'max', 'mean', 'std'])\n",
    "hour_stats_start = hour_stats_start.reset_index()\n",
    "hour_stats_start.columns = hour_cols\n",
    "\n",
    "\n",
    "hour_stats_end = df_train[df_train.distrib_brdr == 0].groupby(['hour'])[['views', 'depth', 'full_reads_percent']].agg(['min', 'max', 'mean', 'std'])\n",
    "hour_stats_end = hour_stats_end.reset_index()\n",
    "hour_stats_end.columns = hour_cols\n",
    "\n",
    "\n",
    "\n",
    "mounth_cols = ['mounth',\n",
    "             'mounth_views_min', 'mounth_views_max', 'mounth_views_mean', 'mounth_views_std',\n",
    "             'mounth_depth_min', 'mounth_depth_max', 'mounth_depth_mean', 'mounth_depth_std',\n",
    "             'mounth_frp_min', 'mounth_frp_max', 'mounth_frp_mean', 'mounth_frp_std',\n",
    "            ]\n",
    "mounth_stats_start = df_train[df_train.distrib_brdr == 1].groupby(['mounth'])[['views', 'depth', 'full_reads_percent']].agg(['min', 'max', 'mean', 'std'])\n",
    "mounth_stats_start = mounth_stats_start.reset_index()\n",
    "mounth_stats_start.columns = mounth_cols\n",
    "\n",
    "mounth_stats_end = df_train[df_train.distrib_brdr == 0].groupby(['mounth'])[['views', 'depth', 'full_reads_percent']].agg(['min', 'max', 'mean', 'std'])\n",
    "mounth_stats_end = mounth_stats_end.reset_index()\n",
    "mounth_stats_end.columns = mounth_cols\n",
    "\n",
    "\n",
    "\n",
    "dow_cols = ['dow',\n",
    "             'dow_views_min', 'dow_views_max', 'dow_views_mean', 'dow_views_std',\n",
    "             'dow_depth_min', 'dow_depth_max', 'dow_depth_mean', 'dow_depth_std',\n",
    "             'dow_frp_min', 'dow_frp_max', 'dow_frp_mean', 'dow_frp_std',\n",
    "            ]\n",
    "dow_stats_start = df_train[df_train.distrib_brdr == 1].groupby(['dow'])[['views', 'depth', 'full_reads_percent']].agg(['min', 'max', 'mean', 'std'])\n",
    "dow_stats_start = dow_stats_start.reset_index()\n",
    "dow_stats_start.columns = dow_cols\n",
    "\n",
    "dow_stats_end = df_train[df_train.distrib_brdr == 0].groupby(['dow'])[['views', 'depth', 'full_reads_percent']].agg(['min', 'max', 'mean', 'std'])\n",
    "dow_stats_end = dow_stats_end.reset_index()\n",
    "dow_stats_end.columns = dow_cols\n",
    "\n",
    "\n",
    "\n",
    "holiday_cols = ['holiday',\n",
    "             'holiday_views_min', 'holiday_views_max', 'holiday_views_mean', 'holiday_views_std',\n",
    "             'holiday_depth_min', 'holiday_depth_max', 'holiday_depth_mean', 'holiday_depth_std',\n",
    "             'holiday_frp_min', 'holiday_frp_max', 'holiday_frp_mean', 'holiday_frp_std',\n",
    "            ]\n",
    "holiday_stats_start = df_train[df_train.distrib_brdr == 1].groupby(['holiday'])[['views', 'depth', 'full_reads_percent']].agg(['min', 'max', 'mean', 'std'])\n",
    "holiday_stats_start = holiday_stats_start.reset_index()\n",
    "holiday_stats_start.columns = holiday_cols\n",
    "\n",
    "holiday_stats_end = df_train[df_train.distrib_brdr == 0].groupby(['holiday'])[['views', 'depth', 'full_reads_percent']].agg(['min', 'max', 'mean', 'std'])\n",
    "holiday_stats_end = holiday_stats_end.reset_index()\n",
    "holiday_stats_end.columns = holiday_cols\n",
    "\n",
    "\n",
    "\n",
    "day_before_holiday_cols = ['day_before_holiday',\n",
    "             'day_before_holiday_views_min', 'day_before_holiday_views_max', 'day_before_holiday_views_mean', 'day_before_holiday_views_std',\n",
    "             'day_before_holiday_depth_min', 'day_before_holiday_depth_max', 'day_before_holiday_depth_mean', 'day_before_holiday_depth_std',\n",
    "             'day_before_holiday_frp_min', 'day_before_holiday_frp_max', 'day_before_holiday_frp_mean', 'day_before_holiday_frp_std',\n",
    "            ]\n",
    "day_before_holiday_stats_start = df_train[df_train.distrib_brdr == 1].groupby(['day_before_holiday'])[['views', 'depth', 'full_reads_percent']].agg(['min', 'max', 'mean', 'std'])\n",
    "day_before_holiday_stats_start = day_before_holiday_stats_start.reset_index()\n",
    "day_before_holiday_stats_start.columns = day_before_holiday_cols\n",
    "\n",
    "day_before_holiday_stats_end = df_train[df_train.distrib_brdr == 0].groupby(['day_before_holiday'])[['views', 'depth', 'full_reads_percent']].agg(['min', 'max', 'mean', 'std'])\n",
    "day_before_holiday_stats_end = day_before_holiday_stats_end.reset_index()\n",
    "day_before_holiday_stats_end.columns = day_before_holiday_cols\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "day_after_holiday_cols = ['day_after_holiday',\n",
    "             'day_after_holiday_views_min', 'day_after_holiday_views_max', 'day_after_holiday_views_mean', 'day_after_holiday_views_std',\n",
    "             'day_after_holiday_depth_min', 'day_after_holiday_depth_max', 'day_after_holiday_depth_mean', 'day_after_holiday_depth_std',\n",
    "             'day_after_holiday_frp_min', 'day_after_holiday_frp_max', 'day_after_holiday_frp_mean', 'day_after_holiday_frp_std',\n",
    "            ]\n",
    "day_after_holiday_stats_start = df_train[df_train.distrib_brdr == 1].groupby(['day_after_holiday'])[['views', 'depth', 'full_reads_percent']].agg(['min', 'max', 'mean', 'std'])\n",
    "day_after_holiday_stats_start = day_after_holiday_stats_start.reset_index()\n",
    "day_after_holiday_stats_start.columns = day_after_holiday_cols\n",
    "\n",
    "day_after_holiday_stats_end = df_train[df_train.distrib_brdr == 0].groupby(['day_after_holiday'])[['views', 'depth', 'full_reads_percent']].agg(['min', 'max', 'mean', 'std'])\n",
    "day_after_holiday_stats_end = day_after_holiday_stats_end.reset_index()\n",
    "day_after_holiday_stats_end.columns = day_after_holiday_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd02b47-c372-49a2-b423-f7a5c99feb02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45e0d770-0859-4d55-a803-49249b7c2a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_daily_stats_date(inp_df:pd.DataFrame, inp_feature, inp_stats_start, inp_stats_end) -> pd.DataFrame:\n",
    "    \n",
    "    \n",
    "    col_x = [el + '_x' for el in inp_stats_start.columns[1:]]\n",
    "    col_y = [el + '_y' for el in inp_stats_start.columns[1:]]\n",
    "    \n",
    "    \n",
    "    tmp = inp_df[['document_id', inp_feature]].merge(inp_stats_start, on = [inp_feature], how = 'left', validate = 'many_to_one')\n",
    "    tmp = tmp.merge(inp_stats_end,   on = [inp_feature], how = 'left', validate = 'many_to_one')\n",
    "    \n",
    "    \n",
    "    for el in inp_stats_start.columns[1:]:\n",
    "        tmp[el] = tmp[f'{el}_x'].fillna(tmp[f'{el}_y'])   \n",
    "\n",
    "    tmp.drop(col_x, inplace = True, axis = 1)\n",
    "    tmp.drop(col_y, inplace = True, axis = 1)\n",
    "    tmp.drop([inp_feature], inplace = True, axis = 1)\n",
    "    \n",
    "    \n",
    "    ret_df = inp_df.merge(tmp, on = ['document_id'], how = 'left', validate = 'one_to_one')\n",
    "    \n",
    "    if inp_stats_start.columns[3] not in clmns['publish_date']['num']:\n",
    "        clmns['publish_date']['num'].extend(inp_stats_start.columns[1:])\n",
    "    \n",
    "    return ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378056eb-86eb-4359-9b29-6ec3d0421d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0381dbf-87f1-414a-adc1-c5df4dfbeb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before  (6981, 34) (3000, 31) add  13\n",
      "before  (6981, 46) (3000, 43) add  13\n"
     ]
    }
   ],
   "source": [
    "print('before ', df_train.shape, df_test.shape, 'add ', hour_stats_start.shape[1])\n",
    "df_train = add_daily_stats_date(df_train, 'hour', hour_stats_start, hour_stats_end)\n",
    "df_test  = add_daily_stats_date(df_test, 'hour', hour_stats_start, hour_stats_end)\n",
    "print('before ', df_train.shape, df_test.shape, 'add ', hour_stats_start.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2434b72f-e39e-48b8-aa9b-d10e3abce11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before  (6981, 46) (3000, 43) add  13\n",
      "before  (6981, 58) (3000, 55) add  13\n"
     ]
    }
   ],
   "source": [
    "print('before ', df_train.shape, df_test.shape, 'add ', mounth_stats_start.shape[1])\n",
    "df_train = add_daily_stats_date(df_train, 'mounth', mounth_stats_start, mounth_stats_end)\n",
    "df_test  = add_daily_stats_date(df_test, 'mounth', mounth_stats_start, mounth_stats_end)\n",
    "print('before ', df_train.shape, df_test.shape, 'add ', mounth_stats_start.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4dd5523e-4b87-4ce9-b174-0bff1ffdca48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before  (6981, 58) (3000, 55) add  13\n",
      "before  (6981, 70) (3000, 67) add  13\n"
     ]
    }
   ],
   "source": [
    "print('before ', df_train.shape, df_test.shape, 'add ', dow_stats_start.shape[1])\n",
    "df_train = add_daily_stats_date(df_train, 'dow', dow_stats_start, dow_stats_end)\n",
    "df_test  = add_daily_stats_date(df_test, 'dow', dow_stats_start, dow_stats_end)\n",
    "print('before ', df_train.shape, df_test.shape, 'add ', dow_stats_start.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8fa73cb-177e-413d-8baf-ffdf6f3febb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before  (6981, 70) (3000, 67) add  13\n",
      "before  (6981, 82) (3000, 79) add  13\n"
     ]
    }
   ],
   "source": [
    "print('before ', df_train.shape, df_test.shape, 'add ', holiday_stats_start.shape[1])\n",
    "df_train = add_daily_stats_date(df_train, 'holiday', holiday_stats_start, holiday_stats_end)\n",
    "df_test  = add_daily_stats_date(df_test, 'holiday', holiday_stats_start, holiday_stats_end)\n",
    "print('before ', df_train.shape, df_test.shape, 'add ', holiday_stats_start.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd29a11c-3b68-43f0-9c05-98f6e1a9536a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before  (6981, 82) (3000, 79) add  13\n",
      "before  (6981, 94) (3000, 91) add  13\n"
     ]
    }
   ],
   "source": [
    "print('before ', df_train.shape, df_test.shape, 'add ', day_before_holiday_stats_start.shape[1])\n",
    "df_train = add_daily_stats_date(df_train, 'day_before_holiday', day_before_holiday_stats_start, day_before_holiday_stats_end)\n",
    "df_test  = add_daily_stats_date(df_test, 'day_before_holiday', day_before_holiday_stats_start, day_before_holiday_stats_end)\n",
    "print('before ', df_train.shape, df_test.shape, 'add ', day_before_holiday_stats_start.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e39cec4-f1cb-46a6-a5a9-0cdf3d18c74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before  (6981, 94) (3000, 91) add  13\n",
      "before  (6981, 106) (3000, 103) add  13\n"
     ]
    }
   ],
   "source": [
    "print('before ', df_train.shape, df_test.shape, 'add ', day_after_holiday_stats_start.shape[1])\n",
    "df_train = add_daily_stats_date(df_train, 'day_after_holiday', day_after_holiday_stats_start, day_after_holiday_stats_end)\n",
    "df_test  = add_daily_stats_date(df_test, 'day_after_holiday', day_after_holiday_stats_start, day_after_holiday_stats_end)\n",
    "print('before ', df_train.shape, df_test.shape, 'add ', day_after_holiday_stats_start.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951fbd28-f04d-4db7-8955-ce2becc9d994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2698b48-ee38-4466-8a1d-f7a02527acdf",
   "metadata": {},
   "source": [
    "Рассчитаем дневные статистики + лаги за 7 дней + разница за 7 дней + гаусиана-тренд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6632adfd-e286-4a6a-b7a7-dadf6cf65968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0 days     6885\n",
       "1 days       93\n",
       "22 days       1\n",
       "5 days        1\n",
       "Name: m_d, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sort_values(by='m_d').m_d.diff().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45214f79-6e72-448d-8049-8187167b6de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_daily_stats(inp_df: pd.DataFrame, max_lags: int = 7) -> pd.DataFrame:\n",
    "    \n",
    "    ret_df = inp_df.sort_values(by='m_d').groupby('m_d')[['m_d', 'views', 'depth', 'full_reads_percent']].agg(['min', 'max', 'mean', 'std']).copy()\n",
    "    new_cols = ['views_min', 'views_max', 'views_mean', 'views_std',\n",
    "                'depth_min', 'depth_max', 'depth_mean', 'depth_std',\n",
    "                'frp_min',   'frp_max',   'frp_mean',   'frp_std',\n",
    "               ]\n",
    "    ret_df.columns = new_cols\n",
    "    ret_df = ret_df.reset_index()\n",
    "    #??????? only std\n",
    "    #ret_df.isnull().sum() > 0\n",
    "    ret_df.fillna(0, inplace = True)\n",
    "    \n",
    "    \n",
    "    # не учитывать результат сегодняшнего дня\n",
    "    for col in new_cols:\n",
    "        ret_df[col] = ret_df[col].shift(1)\n",
    "        \n",
    "    v_std = np.std(ret_df.views_mean)\n",
    "    d_std = np.std(ret_df.depth_mean)\n",
    "    f_std = np.std(ret_df.frp_mean)\n",
    "        \n",
    "    ret_df['view_gaus_2'] = ret_df.views_mean.rolling(2, win_type='gaussian').sum(std = v_std)\n",
    "    ret_df['depth_gaus_2'] = ret_df.depth_mean.rolling(2, win_type='gaussian').sum(std = d_std)\n",
    "    ret_df['frp_gaus_2'] = ret_df.frp_mean.rolling(2, win_type='gaussian').sum(std = f_std)\n",
    "    \n",
    "    ret_df['view_gaus_3'] = ret_df.views_mean.rolling(3, win_type='gaussian').sum(std = v_std)\n",
    "    ret_df['depth_gaus_3'] = ret_df.depth_mean.rolling(3, win_type='gaussian').sum(std = d_std)\n",
    "    ret_df['frp_gaus_3'] = ret_df.frp_mean.rolling(3, win_type='gaussian').sum(std = f_std)\n",
    "    \n",
    "    ret_df['view_gaus_7'] = ret_df.views_mean.rolling(7, win_type='gaussian').sum(std = v_std)\n",
    "    ret_df['depth_gaus_7'] = ret_df.depth_mean.rolling(7, win_type='gaussian').sum(std = d_std)\n",
    "    ret_df['frp_gaus_7'] = ret_df.frp_mean.rolling(7, win_type='gaussian').sum(std = f_std)\n",
    "    \n",
    "\n",
    "    for col, lag in  product(new_cols, list(range(max_lags))):\n",
    "        ret_df[f'{col}_lag{lag+1}'] = ret_df[col].shift(lag+1)\n",
    "        ret_df[f'{col}_dif{lag+1}'] = ret_df[col].diff(lag+1)\n",
    "        #????fillna\n",
    "        #ret_df[f'{col}_lag{lag+1}'].fillna('mean', inplace = True)\n",
    "    \n",
    "\n",
    "    \n",
    "    return ret_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "63081a90-0194-4758-b458-09b989713cca",
   "metadata": {},
   "source": [
    "daily_stats = create_daily_stats(df_train)\n",
    "daily_stats.to_csv(os.path.join(DIR_DATA, 'dayly_stats.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "187a5895-5470-4a2d-8d7b-e139b34b3305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\_v010ch_\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "C:\\Users\\_v010ch_\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "C:\\Users\\_v010ch_\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  \n",
      "C:\\Users\\_v010ch_\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "daily_stats_start = create_daily_stats(df_train[df_train.distrib_brdr == 1])\n",
    "daily_stats_start.to_csv(os.path.join(DIR_DATA, 'daily_stats_start.csv'), index = False)\n",
    "\n",
    "daily_stats_end = create_daily_stats(df_train[df_train.distrib_brdr == 0])\n",
    "daily_stats_end.to_csv(os.path.join(DIR_DATA, 'daily_stats_end.csv'), index = False)\n",
    "\n",
    "\n",
    "daily_stats_start.fillna(daily_stats_start.mean(), inplace = True)\n",
    "daily_stats_end.fillna(daily_stats_end.mean(), inplace = True)\n",
    "\n",
    "for el in daily_stats_start.columns:\n",
    "    if sum(daily_stats_start[el].isna()) != 0:\n",
    "        print(el, sum(daily_stats_start[el].isna()))\n",
    "        \n",
    "    if sum(daily_stats_end[el].isna()) != 0:\n",
    "        print(el, sum(daily_stats_end[el].isna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7289656-abca-4500-a9a6-42489f2ac958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#daily_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27562e9d-1711-42dc-8da4-573be089e40c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4674a89e-5345-4acb-8f7f-9a663a680b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['m_d', 'views_min', 'views_max', 'views_mean', 'views_std', 'depth_min',\n",
       "       'depth_max', 'depth_mean', 'depth_std', 'frp_min',\n",
       "       ...\n",
       "       'frp_std_lag3', 'frp_std_dif3', 'frp_std_lag4', 'frp_std_dif4',\n",
       "       'frp_std_lag5', 'frp_std_dif5', 'frp_std_lag6', 'frp_std_dif6',\n",
       "       'frp_std_lag7', 'frp_std_dif7'],\n",
       "      dtype='object', length=190)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_stats_start.columns[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6d124c-1e44-436f-a4fe-3e3d0bab0263",
   "metadata": {},
   "source": [
    "Добавим их к датасетам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4713d9b-96f6-4caa-976a-8b991b7b7aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_daily_stats(inp_df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    \n",
    "    col_x = [el + '_x' for el in daily_stats_start.columns[1:]]\n",
    "    col_y = [el + '_y' for el in daily_stats_start.columns[1:]]\n",
    "    \n",
    "    \n",
    "    tmp = inp_df[['document_id', 'm_d']].merge(daily_stats_start, on = ['m_d'], how = 'left', validate = 'many_to_one')\n",
    "    #print(tmp.shape)\n",
    "    tmp = tmp.merge(daily_stats_end, on = ['m_d'], how = 'left', validate = 'many_to_one')\n",
    "    #print(tmp.shape)\n",
    "    \n",
    "    for el in daily_stats_start.columns[1:]:\n",
    "        tmp[el] = tmp[f'{el}_x'].fillna(tmp[f'{el}_y'])   \n",
    "\n",
    "    tmp.drop(col_x, inplace = True, axis = 1)\n",
    "    tmp.drop(col_y, inplace = True, axis = 1)\n",
    "    tmp.drop(['m_d'], inplace = True, axis = 1)\n",
    "    \n",
    "    \n",
    "    ret_df = inp_df.merge(tmp, on = ['document_id'], how = 'left', validate = 'one_to_one')\n",
    "    \n",
    "    if daily_stats_start.columns[3] not in clmns['publish_date']['num']:\n",
    "        clmns['publish_date']['num'].extend(daily_stats_start.columns[1:])\n",
    "    \n",
    "    return ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "685a44c6-375a-4c5e-a92d-d82ed85dee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_daily_stats___(inp_df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    #ret_df = inp_df.merge(daily_stats, on = 'm_d', validate = 'many_to_one')\n",
    "    ret_df = inp_df.merge(daily_stats, on = 'm_d', how = 'left', validate = 'many_to_one')\n",
    "    \n",
    "    if 'views_min' not in clmns['publish_date']['num']:\n",
    "        clmns['publish_date']['num'].extend(daily_stats.columns[1:])\n",
    "    \n",
    "    return ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af66509c-3085-4f2b-8605-bd67e8340066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before  (6981, 106) (3000, 103) add  190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\_v010ch_\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after   (6981, 295) (3000, 292)\n"
     ]
    }
   ],
   "source": [
    "print('before ', df_train.shape, df_test.shape, 'add ', daily_stats_start.shape[1])\n",
    "df_train = add_daily_stats(df_train)\n",
    "df_test  = add_daily_stats(df_test)\n",
    "print('after  ', df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfc1bd5-7df3-419e-bc5a-fc4d008b853f",
   "metadata": {},
   "source": [
    "Проверим на пропуски в тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7fe4552f-e958-4b34-9aa6-673425cba3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "views_min     6\n",
       "views_max     6\n",
       "views_mean    6\n",
       "views_std     6\n",
       "depth_min     6\n",
       "depth_max     6\n",
       "depth_mean    6\n",
       "depth_std     6\n",
       "frp_min       6\n",
       "frp_max       6\n",
       "frp_mean      6\n",
       "frp_std       6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['views_min', 'views_max', 'views_mean', 'views_std',\n",
    "            'depth_min', 'depth_max', 'depth_mean', 'depth_std',\n",
    "            'frp_min',   'frp_max',   'frp_mean',   'frp_std']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4d73fa-1fb8-4de9-a52f-5c0c97d7b77c",
   "metadata": {},
   "source": [
    "да, на начальныз лагах есть пропуски.    \n",
    "заменять будем уже при подборе и построении моделей   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864c75e8-54f7-40f9-9bec-ac6a74b5d7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7f29aa-7897-4934-a7d2-67d7d18cbf16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7e3585-03f6-43e8-a1fd-1ee97b86d4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14356cdb-23e9-4c54-92cd-d5ef8f053fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6674236c-986e-400d-9b33-287c8d3291a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1f207ab-ebe8-4a17-98e7-934eb6b30274",
   "metadata": {},
   "source": [
    "# title 2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e213f9d4-39b8-477c-8813-45a351bbf34f",
   "metadata": {},
   "source": [
    "%%time\n",
    "tmp = df_train[['m_d', 'true_title']]\n",
    "tmp = pd.concat([tmp, df_test[['m_d', 'true_title']]], \n",
    "                ignore_index = True, axis = 0)\n",
    "\n",
    "tmp['covid']     = tmp.true_title.apply(lambda x: 1 if 'COVID' in x else 0)\n",
    "tmp['ukr']       = tmp.true_title.apply(lambda x: 1 if 'Укр' in x else 0)\n",
    "tmp['sanctions'] = tmp.true_title.apply(lambda x: 1 if 'анкц' in x else 0)\n",
    "\n",
    "#tmp.groupby('m_d')[['covid', 'sanctions']].agg('size')\n",
    "\n",
    "df_train = df_train.merge(tmp.groupby('m_d')[['covid']].agg('size').rename('covid'),\n",
    "                          on = ['m_d'], how = 'left', validate = 'many_to_one'\n",
    "                         )\n",
    "df_tets = df_test.merge(tmp.groupby('m_d')[['covid']].agg('size').rename('covid'),\n",
    "                          on = ['m_d'], how = 'left', validate = 'many_to_one'\n",
    "                         )\n",
    "\n",
    "df_train = df_train.merge(tmp.groupby('m_d')[['ukr']].agg('size').rename('ukr'),\n",
    "                          on = ['m_d'], how = 'left', validate = 'many_to_one'\n",
    "                         )\n",
    "df_test = df_test.merge(tmp.groupby('m_d')[['ukr']].agg('size').rename('ukr'),\n",
    "                          on = ['m_d'], how = 'left', validate = 'many_to_one'\n",
    "                         )\n",
    "\n",
    "\n",
    "df_train = df_train.merge(tmp.groupby('m_d')[['sanctions']].agg('size').rename('sanctions'),\n",
    "                          on = ['m_d'], how = 'left', validate = 'many_to_one'\n",
    "                         )\n",
    "df_test = df_test.merge(tmp.groupby('m_d')[['sanctions']].agg('size').rename('sanctions'),\n",
    "                          on = ['m_d'], how = 'left', validate = 'many_to_one'\n",
    "                         )\n",
    "\n",
    "clmns['title']['num'].extend(['sanctions', 'ukr', 'covid'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b720dd93-1b7d-4e82-9fc7-4ae8aec9496e",
   "metadata": {},
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2463bfed-cab2-4921-bfd8-7d5d15a08acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee016917-e2e2-41a2-8a73-c7fa96c15aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0325a77e-b14d-4ba1-b6c3-08918561f8a7",
   "metadata": {},
   "source": [
    "## session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd8a217-23ce-4d79-a726-40f5e51b7fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec0a4b71-4077-468c-aea7-4d8593da13fc",
   "metadata": {},
   "source": [
    "## authors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ce0b6b-5419-4eca-b080-45bb9fb794b1",
   "metadata": {},
   "source": [
    "Авторы считываются как строки, а не как массив строк. исправим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2fdf9eb-9f19-4aac-9896-af18c7a3e6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_authors(inp_df): \n",
    "\n",
    "    \n",
    "    inp_df[\"authors_int\"] = inp_df.authors.astype('category')\n",
    "    inp_df[\"authors_int\"] = inp_df.authors_int.cat.codes\n",
    "    inp_df[\"authors_int\"] = inp_df.authors_int.astype('int')\n",
    "    \n",
    "    \n",
    "    inp_df['authors'] = inp_df.authors.apply(lambda x: literal_eval(x))\n",
    "    inp_df['authors'] = inp_df.authors.apply(lambda x: x if len(x) > 0 else ['without_author'])\n",
    "    \n",
    "    inp_df['Nauthors']   = inp_df.authors.apply(lambda x: len(x))\n",
    "    inp_df['Nauthors_2'] = inp_df.Nauthors.apply(lambda x: 1 / (x+1)**2)\n",
    "    inp_df['Nauthors_3'] = inp_df.Nauthors.apply(lambda x: -1 / (x+1)**2)\n",
    "    \n",
    "    if 'authors_int' not in clmns['authors']['num']:\n",
    "        clmns['authors']['num'].extend(['authors_int'])\n",
    "    \n",
    "    if 'Nauthors' not in clmns['authors']['num']:\n",
    "        clmns['authors']['num'].extend(['Nauthors', 'Nauthors_2', 'Nauthors_3'])\n",
    "    \n",
    "    return inp_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c565aa3e-e022-49be-a40e-96c5d5f77a9b",
   "metadata": {},
   "source": [
    "df_train['authors']  = df_train.authors.apply(lambda x: literal_eval(x))\n",
    "df_test['authors']   = df_test.authors.apply( lambda x: literal_eval(x))\n",
    "\n",
    "# пустое поле автора заменим на значение, что автор не указан\n",
    "df_train['authors'] = df_train['authors'].apply(lambda x: x if len(x) > 0 else ['without_author'])\n",
    "df_test['authors']  = df_test['authors'].apply( lambda x: x if len(x) > 0 else ['without_author'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f4e18af-cc58-4daa-bce6-50f7446465d2",
   "metadata": {},
   "source": [
    "df_train['Nauthors'] = df_train.authors.apply(lambda x: len(x))\n",
    "df_test['Nauthors']  = df_test.authors.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0542f9c5-2ea9-458a-942b-6477c43f7e89",
   "metadata": {},
   "source": [
    "clmns['authors']['num'].extend(['Nauthors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c97eefe4-fccc-4da3-9d07-1b93cb79c525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before  (6981, 295) (3000, 292)\n",
      "after   (6981, 299) (3000, 296)\n"
     ]
    }
   ],
   "source": [
    "print('before ', df_train.shape, df_test.shape)\n",
    "df_train = prep_authors(df_train)\n",
    "df_test  = prep_authors(df_test)\n",
    "print('after  ', df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a9005-15b6-4cce-9570-b9d218ebbd01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d20ec8dc-f694-4ff0-91a5-f801224a0d07",
   "metadata": {},
   "source": [
    "выделяем всех авторов в трейне"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3bb962bf-e87d-4bef-aee8-751af296081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_authors = set()\n",
    "for el in df_train.authors.values:\n",
    "    if len (el) == 0:\n",
    "        continue\n",
    "    if len(el) == 1:\n",
    "        all_authors.add(el[0])\n",
    "        continue\n",
    "        \n",
    "    for author in el:\n",
    "        all_authors.add(author)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647368f4-e838-438d-9157-fe75cdeeb2e6",
   "metadata": {},
   "source": [
    "проверяем на наличия авторов из теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48970f9e-293d-4279-9e71-e25d575062a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5a2511349a794727e3fa3d20\n",
      "57f766ae9a79479bfcfa0133\n"
     ]
    }
   ],
   "source": [
    "test_authors = set()\n",
    "for el in df_test.authors.values:\n",
    "    if len (el) == 0:\n",
    "        continue\n",
    "    if len(el) == 1:\n",
    "        test_authors.add(el[0])\n",
    "        continue\n",
    "        \n",
    "    for author in el:\n",
    "        test_authors.add(author)\n",
    "\n",
    "for el in test_authors:\n",
    "    if el not in all_authors:\n",
    "        print(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148997dd-8034-47d0-ae51-fb935d9559ea",
   "metadata": {},
   "source": [
    "2х авторов нет в трейне.   \n",
    "предположительно заменим их статистики средними."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb8c209-663d-4bac-ae01-3b4349522b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81e6ba67-6954-4ff9-8873-46b7984495d9",
   "metadata": {},
   "source": [
    "Все статьи автора (с учетом совместных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "778d462f-7324-4e9c-bd56-5713b8fb6fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 6981/6981 [00:00<00:00, 776751.81it/s]\n"
     ]
    }
   ],
   "source": [
    "auth_doc_id = {el: [] for el in all_authors}\n",
    "\n",
    "for el in tqdm(df_train.loc[:, ['document_id', 'authors']].values):\n",
    "    for athr in range(len(el[1])):\n",
    "        auth_doc_id[el[1][athr]].append(el[0])\n",
    "        \n",
    "with open(os.path.join(DIR_DATA, 'authors_all.pkl'), 'wb') as pkl_file:\n",
    "    pkl.dump(auth_doc_id, pkl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39055cc8-db6d-484f-a233-ebaa95eef3b1",
   "metadata": {},
   "source": [
    "Статьи только автора (в одиночку)(пока не применяется)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "595a8c1d-bc76-42dd-adb9-0511cd326a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 6981/6981 [00:00<00:00, 994377.38it/s]\n"
     ]
    }
   ],
   "source": [
    "auth_doc_id_alone = {el: [] for el in all_authors}\n",
    "\n",
    "for el in tqdm(df_train.loc[:, ['document_id', 'authors']].values):\n",
    "    if len(el[1]) == 1:\n",
    "        auth_doc_id_alone[el[1][0]].append(el[0])\n",
    "        \n",
    "with open(os.path.join(DIR_DATA, 'authors_alone.pkl'), 'wb') as pkl_file:\n",
    "    pkl.dump(auth_doc_id_alone, pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a59ea06-5f22-432d-9810-b1fb64e985be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49ee5791-cd95-4470-be98-c5916d08583a",
   "metadata": {},
   "source": [
    "Соберем статистику по авторам (с учетом совместных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c91c21ca-173b-43c2-a44b-d8a3522b9226",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_columns = ['author', 'author_size', 'v_auth_min', 'v_auth_max', 'v_auth_mean', 'v_auth_std', 'd_auth_min',\n",
    "                  'd_auth_max', 'd_auth_mean', 'd_auth_std', 'f_auth_min', 'f_auth_max', 'f_auth_mean', 'f_auth_std',\n",
    "                 ]\n",
    "\n",
    "author_group_columns = ['author_size', \n",
    "                        'v_auth_min', 'v_auth_max', 'v_auth_mean', 'v_auth_std',\n",
    "                        'author_size2',\n",
    "                        'd_auth_min', 'd_auth_max', 'd_auth_mean', 'd_auth_std',\n",
    "                        'author_size3',\n",
    "                        'f_auth_min', 'f_auth_max', 'f_auth_mean', 'f_auth_std',\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ec44696-4efa-4974-83cf-68e4182c2f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 101/101 [00:01<00:00, 60.51it/s]\n",
      "C:\\Users\\_v010ch_\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n"
     ]
    }
   ],
   "source": [
    "df_author = pd.DataFrame(columns = author_columns)\n",
    "df_author.author = list(all_authors)\n",
    "\n",
    "for el in tqdm(all_authors):\n",
    "    # определяем статьи текущего автора\n",
    "    df_train['cur_author'] = df_train.authors.apply(lambda x: 1 if el in x else 0)\n",
    "    \n",
    "    # собираем статистики текущего автора\n",
    "    tmp = df_train.groupby('cur_author')[['views', 'depth', 'full_reads_percent']].agg(['size', 'min', 'max', 'mean', 'std'])\n",
    "    tmp.columns = author_group_columns\n",
    "    tmp.reset_index(inplace = True)\n",
    "    tmp.drop(['author_size2', 'author_size3'], axis = 1, inplace = True)\n",
    "    \n",
    "    # сохраняем полученные статистики в DataFrame\n",
    "    df_author.loc[df_author.query('author == @el').index, author_columns[1:]] = tmp.query('cur_author == 1')[tmp.columns[1:]].values[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "# для 2х неизвестных авторов из теста добавим их средними\n",
    "# правильнее бы добавить в функцию добавления статистки, а не в сам DataFrame\n",
    "# однако на данном этапе такой вариант нас более чем устроит\n",
    "#'5a2511349a794727e3fa3d20'\n",
    "#'57f766ae9a79479bfcfa0133'\n",
    "df_author.loc['mean'] = df_author.mean()\n",
    "df_author.loc['mean2'] = df_author.loc['mean']\n",
    "\n",
    "df_author.loc['mean', ['author']] = '5a2511349a794727e3fa3d20'\n",
    "df_author.loc['mean2', ['author']] = '57f766ae9a79479bfcfa0133'\n",
    "\n",
    "df_train.drop(['cur_author'], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e74147b6-e70a-47ea-8e67-af368a051d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_author.to_csv(os.path.join(DIR_DATA, 'author_together.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f42ca482-5d48-4f62-b930-e5d4ece3244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_author.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846bbc4c-13ae-4176-861b-c6bca5ad474d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdc2daaf-c52d-4cb3-a1fa-6779a8838797",
   "metadata": {},
   "source": [
    "Добавляем статистики по авторам в датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9ae93ca-7769-46e1-b46b-185d907f5f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_author_statistics(inp_df):\n",
    "    \n",
    "    if len(inp_df[0]) == 0:  # заменяли на without_author так что не может быть\n",
    "        print(inp_Df)\n",
    "    elif len(inp_df[0]) == 1:\n",
    "        return df_author.loc[df_author.author == inp_df[0][0], \n",
    "                              author_columns[2:]\n",
    "                            ].values[0]\n",
    "    else:\n",
    "        ret_np  = np.zeros(shape = (len(author_columns[2:]),) )\n",
    "        divisor = len(inp_df[0])\n",
    "        \n",
    "        # если авторо больше одного будем выбират средние/мин/макс наченяи среди них\n",
    "        for el in inp_df[0]:\n",
    "            if el in df_author.author.values:\n",
    "                tmp = df_author[df_author.author == el]\n",
    "                ret_np = [ret_np[0]  + tmp.v_auth_min.values[0],\n",
    "                          ret_np[1]  + tmp.v_auth_max.values[0],\n",
    "                          ret_np[2]  + tmp.v_auth_mean.values[0],\n",
    "                          ret_np[3]  + tmp.v_auth_std.values[0],\n",
    "                          ret_np[4]  + tmp.d_auth_min.values[0],\n",
    "                          ret_np[5]  + tmp.d_auth_max.values[0],\n",
    "                          ret_np[6]  + tmp.d_auth_mean.values[0],\n",
    "                          ret_np[7]  + tmp.d_auth_std.values[0],\n",
    "                          ret_np[8]  + tmp.f_auth_min.values[0],\n",
    "                          ret_np[9]  + tmp.f_auth_max.values[0],\n",
    "                          ret_np[10] + tmp.f_auth_mean.values[0],\n",
    "                          ret_np[11] + tmp.f_auth_std.values[0]\n",
    "                         ]\n",
    "            else: # aouthor in test out from train\n",
    "                #divisor -= 1\n",
    "                ret_np = [ret_np[0]  + 0,\n",
    "                          ret_np[1]  + 0,\n",
    "                          ret_np[2]  + 0,\n",
    "                         ret_np[3]  + 0,\n",
    "                         ret_np[4]  + 0,\n",
    "                          ret_np[5]  + 0,\n",
    "                          ret_np[6]  + 0,\n",
    "                          ret_np[7]  + 0,\n",
    "                          ret_np[8]  + 0,\n",
    "                         ret_np[9]  + 0,\n",
    "                          ret_np[10] + 0,\n",
    "                         ret_np[11] + 0\n",
    "                         ]\n",
    "                \n",
    "        #№ пока только среднее\n",
    "        ret_np = [ret_np[0]  / divisor,   # v_auth_min OR MIN\n",
    "                  ret_np[1]  / divisor,   # v_auth_max OR MAX\n",
    "                  ret_np[2]  / divisor,   # v_auth_mean\n",
    "                  ret_np[3]  / divisor,   # v_auth_std\n",
    "                  ret_np[4]  / divisor,   # d_auth_min OR MIN\n",
    "                  ret_np[5]  / divisor,   # d_auth_max OR MAX\n",
    "                  ret_np[6]  / divisor,   # d_auth_mean\n",
    "                  ret_np[7]  / divisor,   # d_auth_std\n",
    "                  ret_np[8]  / divisor,   # f_auth_min OR MIN\n",
    "                  ret_np[9]  / divisor,   # f_auth_max OR MAX\n",
    "                  ret_np[10] / divisor,   # f_auth_mean\n",
    "                  ret_np[11] / divisor,   # f_auth_std\n",
    "                 ]\n",
    "        \n",
    "    return ret_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "de5a47d4-47af-46c4-b28f-cf063aa6c1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_author_features(inp_df):\n",
    "    \n",
    "    tmp_cols = inp_df.columns\n",
    "    author_stats = inp_df[['authors']].progress_apply(add_author_statistics, axis = 1)\n",
    "    inp_df = pd.concat([inp_df, \n",
    "                      pd.DataFrame(author_stats.to_list(), columns = author_columns[2:])], \n",
    "                      ignore_index = True, axis = 1)\n",
    "    \n",
    "    inp_df.columns = list(tmp_cols) + list(author_columns[2:])\n",
    "    \n",
    "    if author_columns[5] not in clmns['authors']['num']:\n",
    "        clmns['authors']['num'].extend(author_columns[2:]) \n",
    "    \n",
    "    return inp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00ecb3de-cfec-487f-893f-6bdf66584ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before (6981, 299) (3000, 296)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6981/6981 [00:05<00:00, 1229.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 3000/3000 [00:02<00:00, 1281.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after (6981, 311) (3000, 308)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# кроме полей author / author_size\n",
    "print('before', df_train.shape, df_test.shape)\n",
    "df_train = add_author_features(df_train)\n",
    "df_test  = add_author_features(df_test)\n",
    "print('after', df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ecf122a4-7283-4af2-a493-4756fb928506",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clmns['authors']['num'].extend(author_columns[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "54767dc3-75e3-491d-830c-60be27ce12f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(tmp_cols) + list(author_columns[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6677e5e-0c12-4689-9d04-e5c777926fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041ccc09-3920-4d6c-828c-b972cd05ef3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225232e5-aba4-4e75-9af5-1cfc618ca59b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6733ce2d-21d6-4d37-8b54-e2ed3c9cf128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "809f01b0-998c-4508-bde1-dc6356354d3c",
   "metadata": {},
   "source": [
    "## ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9ed041db-ce4c-419c-86ed-a3795380cdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.731319005071247"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crt_replace = df_train[df_train.ctr > 0].ctr.mean()\n",
    "crt_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "51b89e9d-98f0-4cf3-8663-5e850223ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ctr_features(inp_df):\n",
    "    \n",
    "    #inp_df['spec_event_1'] = inp_df.ctr.apply(lambda x: 1 if x == 6.096 else 0)\n",
    "    \n",
    "    inp_df.ctr.replace(0.0, crt_replace, inplace = True)\n",
    "    inp_df['ctr_2'] = inp_df.ctr.apply(lambda x: np.sqrt(x))\n",
    "    \n",
    "    #if 'spec_event_1' not in clmns['ctr']['both']:\n",
    "    #    clmns['ctr']['both'].extend(['spec_event_1']) \n",
    "    \n",
    "    if 'ctr_2' not in clmns['ctr']['num']:\n",
    "        clmns['ctr']['num'].extend(['ctr_2']) \n",
    "                                       \n",
    "    return inp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bcd5cdbd-638c-45f8-8c59-f9ba93381c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before  (6981, 311) (3000, 308)\n",
      "after   (6981, 312) (3000, 309)\n"
     ]
    }
   ],
   "source": [
    "print('before ', df_train.shape, df_test.shape)\n",
    "df_train = add_ctr_features(df_train)\n",
    "df_test  = add_ctr_features(df_test)\n",
    "print('after  ', df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a7edd4b1-2336-449b-b2dd-aee150bee984",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['spec'] = df_test.ctr.apply(lambda x: 1 if x == CTR_UKR else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4853c67-38ab-4bed-a8fa-87d33166e83f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c33865-01da-419d-b600-bc88d035d42e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ec713e2b-fb78-4348-9e07-ce3b1ec0dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ctr' not in clmns['ctr']['num']:\n",
    "    clmns['ctr']['num'].extend(['ctr']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3658af95-84e7-483a-8331-97285c391007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abf5218-cc7f-40d6-97e1-3e3c86f73f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcca8b1-6abc-4b98-b89e-36e698bdf456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c6735e-f38c-4f2d-a53a-5d9742068378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f5e911-5c1b-44dc-aef2-dbef0dce3613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0c41832-2fd2-4fe6-ac60-2fc5dc762d20",
   "metadata": {},
   "source": [
    "## category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f625d452-8cd5-4410-af35-17b5ab0cec8e",
   "metadata": {},
   "source": [
    "Собираем статистики по категориям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2019036b-20a9-4d04-8647-3f802be36efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_daily_stats_by_category(inp_df: pd.DataFrame, max_lags: int = 7) -> pd.DataFrame:\n",
    "    \n",
    "    ret_df = inp_df[['publish_date', 'm_d', 'category', 'views', 'depth', 'full_reads_percent']].copy()\n",
    "    new_cols = ['cat_views_min', 'cat_views_max', 'cat_views_mean', 'cat_views_std',\n",
    "                'cat_depth_min', 'cat_depth_max', 'cat_depth_mean', 'cat_depth_std',\n",
    "                'cat_frp_min',   'cat_frp_max',   'cat_frp_mean',   'cat_frp_std',\n",
    "               ]\n",
    "    \n",
    "    ret_df.sort_values(by=['publish_date'], inplace = True)\n",
    "    ret_df = ret_df.groupby(['category', 'm_d'])['views', 'depth', 'full_reads_percent'].agg(('min', 'max', 'mean', 'std'))\n",
    "        \n",
    "    ret_df.columns = new_cols\n",
    "    ret_df = ret_df.reset_index()\n",
    "    #??????? only std\n",
    "    #ret_df.isnull().sum() > 0\n",
    "    ret_df.fillna(0, inplace = True)\n",
    "    \n",
    "    for col in new_cols:\n",
    "        ret_df[col] = ret_df[col].shift(1)\n",
    "    \n",
    "    \n",
    "    v_std = np.std(ret_df.cat_views_mean)\n",
    "    d_std = np.std(ret_df.cat_depth_mean)\n",
    "    f_std = np.std(ret_df.cat_frp_mean)\n",
    "    \n",
    "    ret_df['cat_view_gaus_2'] = ret_df.cat_views_mean.rolling(2, win_type='gaussian').sum(std = v_std)\n",
    "    ret_df['cat_depth_gaus_2'] = ret_df.cat_depth_mean.rolling(2, win_type='gaussian').sum(std = d_std)\n",
    "    ret_df['cat_frp_gaus_2'] = ret_df.cat_frp_mean.rolling(2, win_type='gaussian').sum(std = f_std)\n",
    "    \n",
    "    ret_df['cat_view_gaus_3'] = ret_df.cat_views_mean.rolling(3, win_type='gaussian').sum(std = v_std)\n",
    "    ret_df['cat_depth_gaus_3'] = ret_df.cat_depth_mean.rolling(3, win_type='gaussian').sum(std = d_std)\n",
    "    ret_df['cat_frp_gaus_3'] = ret_df.cat_frp_mean.rolling(3, win_type='gaussian').sum(std = f_std)\n",
    "    \n",
    "    ret_df['cat_view_gaus_7'] = ret_df.cat_views_mean.rolling(7, win_type='gaussian').sum(std = v_std)\n",
    "    ret_df['cat_depth_gaus_7'] = ret_df.cat_depth_mean.rolling(7, win_type='gaussian').sum(std = d_std)\n",
    "    ret_df['cat_frp_gaus_7'] = ret_df.cat_frp_mean.rolling(7, win_type='gaussian').sum(std = f_std)\n",
    "    \n",
    "    for col, lag in  product(new_cols, list(range(max_lags))):\n",
    "        ret_df[f'{col}_lag{lag+1}'] = ret_df[col].shift(lag+1)\n",
    "        ret_df[f'{col}_dif{lag+1}'] = ret_df[col].diff(lag+1)\n",
    "        \n",
    "        #????fillna\n",
    "        #ret_df[f'{col}_lag{lag+1}'].fillna('mean', inplace = True)\n",
    "    \n",
    "\n",
    "        \n",
    "    return ret_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d441dea7-7587-483e-a195-bab212b895f2",
   "metadata": {},
   "source": [
    "if not os.path.exists(os.path.join(DIR_DATA, 'daily_stats_category.csv')):\n",
    "    daily_stats_category = create_daily_stats_by_category(df_train)\n",
    "    daily_stats_category.to_csv(os.path.join(DIR_DATA, 'daily_stats_category.csv'), index = False)\n",
    "else:\n",
    "    daily_stats_category = pd.read_csv(os.path.join(DIR_DATA, 'daily_stats_category.csv'))#, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6e9355e3-fcf0-40e4-aa90-23c2c5dfd890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\_v010ch_\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\_v010ch_\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "C:\\Users\\_v010ch_\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "C:\\Users\\_v010ch_\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  \n",
      "C:\\Users\\_v010ch_\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "daily_stats_cat_start = create_daily_stats_by_category(df_train[df_train.distrib_brdr == 1])\n",
    "daily_stats_cat_start.to_csv(os.path.join(DIR_DATA, 'daily_stats_cat_start.csv'), index = False)\n",
    "\n",
    "daily_stats_cat_end = create_daily_stats_by_category(df_train[df_train.distrib_brdr == 0])\n",
    "daily_stats_cat_end.to_csv(os.path.join(DIR_DATA, 'daily_stats_cat_end.csv'), index = False)\n",
    "\n",
    "\n",
    "daily_stats_cat_start.fillna(daily_stats_cat_start.mean(), inplace = True)\n",
    "daily_stats_cat_end.fillna(daily_stats_cat_end.mean(), inplace = True)\n",
    "\n",
    "for el in daily_stats_cat_start.columns:\n",
    "    if sum(daily_stats_cat_start[el].isna()) != 0:\n",
    "        print(el, sum(daily_stats_cat_start[el].isna()))\n",
    "        \n",
    "    if sum(daily_stats_cat_end[el].isna()) != 0:\n",
    "        print(el, sum(daily_stats_cat_end[el].isna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "23f0dba0-a042-4ed0-8888-c7779a45a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.std(daily_stats_category.cat_frp_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af31136e-2fc0-45ac-8ae6-5626314cefc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06faed46-e104-414c-901b-1c84d59f5647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c97a7418-e6a6-4fee-aa95-9902562220cf",
   "metadata": {},
   "source": [
    "Добавляем статистики по категориям в датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a064783a-074e-4f30-a7ea-fd81022d2ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.m_d\n",
    "#daily_stats_cat_end.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1c07fee4-9b43-4ccc-b330-e3971e7b107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_daily_stats_category(inp_df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    \n",
    "    col_x = [el + '_x' for el in daily_stats_cat_start.columns[2:]]\n",
    "    col_y = [el + '_y' for el in daily_stats_cat_start.columns[2:]]\n",
    "    \n",
    "    \n",
    "    tmp = inp_df[['document_id', 'category', 'm_d']].merge(daily_stats_cat_start, on = ['category', 'm_d'], how = 'left', validate = 'many_to_one')\n",
    "    tmp = tmp.merge(daily_stats_cat_end,   on = ['category', 'm_d'], how = 'left', validate = 'many_to_one')\n",
    "    \n",
    "    \n",
    "    for el in daily_stats_cat_start.columns[2:]:\n",
    "        tmp[el] = tmp[f'{el}_x'].fillna(tmp[f'{el}_y'])   \n",
    "\n",
    "    tmp.drop(col_x, inplace = True, axis = 1)\n",
    "    tmp.drop(col_y, inplace = True, axis = 1)\n",
    "    tmp.drop(['category', 'm_d'], inplace = True, axis = 1)\n",
    "    \n",
    "    \n",
    "    ret_df = inp_df.merge(tmp, on = ['document_id'], how = 'left', validate = 'one_to_one')\n",
    "    \n",
    "    if daily_stats_cat_start.columns[3] not in clmns['category']['num']:\n",
    "        clmns['category']['num'].extend(daily_stats_cat_start.columns[2:])\n",
    "    \n",
    "    return ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "537f84e4-ae91-4aef-8e9e-eca9db3bda58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_daily_stats_category__(inp_df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    ret_df = inp_df.merge(daily_stats_category, on = ['category', 'm_d'], how = 'left', validate = 'many_to_one')\n",
    "    \n",
    "    if daily_stats_category.columns[3] not in clmns['category']['num']:\n",
    "        clmns['category']['num'].extend(daily_stats_category.columns[2:])\n",
    "    \n",
    "    return ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "95ada5f6-7a32-4e4d-8e3e-7f6fad02280e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before  (6981, 312) (3000, 310) add  (222, 191) 191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\_v010ch_\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after   (6981, 501) (3000, 499)\n"
     ]
    }
   ],
   "source": [
    "print('before ', df_train.shape, df_test.shape, 'add ', daily_stats_cat_start.shape, len(daily_stats_cat_start.columns))\n",
    "#print('before ', df_train.shape, df_test.shape, 'add ', daily_stats_category.shape, len(daily_stats_category.columns))\n",
    "df_train = add_daily_stats_category(df_train)\n",
    "df_test = add_daily_stats_category(df_test)\n",
    "print('after  ', df_train.shape, df_test.shape, )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8adc546f-2fda-40ab-b2aa-8191ed0fdaa2",
   "metadata": {},
   "source": [
    "col_x = [el + '_x' for el in daily_stats_cat_start.columns[2:]]\n",
    "col_y = [el + '_y' for el in daily_stats_cat_start.columns[2:]]\n",
    "\n",
    "tmp = df_train[['document_id', 'category', 'm_d']].merge(daily_stats_cat_start, on = ['category', 'm_d'], how = 'left', validate = 'many_to_one')\n",
    "tmp = tmp.merge(daily_stats_cat_end,   on = ['category', 'm_d'], how = 'left', validate = 'many_to_one')\n",
    "\n",
    "for el in daily_stats_cat_start.columns[2:]:\n",
    "    tmp[el] = tmp[f'{el}_x'].fillna(tmp[f'{el}_y'])    \n",
    "#tmp[daily_stats_cat_start.columns[2:]] = tmp[col_x].fillna(tmp[col_y])\n",
    "\n",
    "tmp.drop(col_x, inplace = True, axis = 1)\n",
    "tmp.drop(col_y, inplace = True, axis = 1)\n",
    "\n",
    "for el in daily_stats_cat_start.columns[2:]:\n",
    "    if sum(tmp[el].isna()) != 0:\n",
    "        print('wtf ', el, ' ',sum(tmp[el].isna()))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5c7d83-0ece-4953-8856-1200abf35b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d86df54a-8526-46f9-98a7-9c6ff15a8326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(' '.join(df_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6c65ee-51c9-44fd-866a-84dbae7d9e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482c824a-f9e5-4868-987a-a1040020e070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "84fa71e7-c530-4da4-935c-c6b6d8af6a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clmns['category']['num'].extend(daily_stats_category.columns[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba08916-2ce6-462e-b442-2c6c6bcf10b2",
   "metadata": {},
   "source": [
    "Проверяем, что все данные есть в тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "201340b2-5f89-4257-8113-ad91b253da39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat_views_min       33\n",
       "cat_views_max       33\n",
       "cat_views_mean      33\n",
       "cat_views_std       33\n",
       "cat_depth_min       33\n",
       "                    ..\n",
       "cat_frp_std_dif5    33\n",
       "cat_frp_std_lag6    33\n",
       "cat_frp_std_dif6    33\n",
       "cat_frp_std_lag7    33\n",
       "cat_frp_std_dif7    33\n",
       "Length: 189, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_test[['cat_views_min', 'cat_views_max', 'cat_views_mean', 'cat_views_std',\n",
    "#                'cat_depth_min', 'cat_depth_max', 'cat_depth_mean', 'cat_depth_std',\n",
    "#               'cat_frp_min',   'cat_frp_max',   'cat_frp_mean',   'cat_frp_std',]].isnull().sum()\n",
    "df_test[daily_stats_cat_start.columns[2:]].isnull().sum()\n",
    "#df_test[daily_stats_category.columns[2:]].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61fc93e-d6a5-4b7d-8a20-9ae511ae78a9",
   "metadata": {},
   "source": [
    "Значения в признаках с лагами могут отсутствовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e7bc40-244b-490d-9b97-0b242ab507f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8188e5c0-551f-48e2-bbdd-df408909a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_category(inp_df):\n",
    "    \n",
    "    inp_df[\"category_int\"] = inp_df.category.astype('category')\n",
    "    inp_df[\"category_int\"] = inp_df.category_int.cat.codes\n",
    "    inp_df[\"category_int\"] = inp_df.category_int.astype('int')\n",
    "    \n",
    "    if 'category_int' not in clmns['category']['num']:\n",
    "        clmns['category']['num'].extend(['category_int'])\n",
    "    \n",
    "    \n",
    "    if 'category' not in clmns['category']['cat']:\n",
    "        clmns['category']['cat'].extend(['category'])\n",
    "    \n",
    "    return inp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ceb51afd-6afa-4a3f-a9bb-0c879dcf0bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before  (6981, 501) (3000, 499)\n",
      "after   (6981, 502) (3000, 500)\n"
     ]
    }
   ],
   "source": [
    "print('before ', df_train.shape, df_test.shape,)\n",
    "df_train = prep_category(df_train)\n",
    "df_test = prep_category(df_test)\n",
    "print('after  ', df_train.shape, df_test.shape, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2e214271-0545-4c44-86a2-06984ae7e664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['document_id', 'title', 'publish_date', 'session', 'authors', 'ctr',\n",
       "       'category', 'tags', 'views', 'depth',\n",
       "       ...\n",
       "       'cat_frp_std_dif3', 'cat_frp_std_lag4', 'cat_frp_std_dif4',\n",
       "       'cat_frp_std_lag5', 'cat_frp_std_dif5', 'cat_frp_std_lag6',\n",
       "       'cat_frp_std_dif6', 'cat_frp_std_lag7', 'cat_frp_std_dif7',\n",
       "       'category_int'],\n",
       "      dtype='object', length=502)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367da552-2621-4d7d-b158-7d338c49b13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83bf589-1fdc-44ca-9257-b901f7b91916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5afbefd-6328-4a74-bc9a-c6e701b3e7fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fecc672-ad0e-4e71-96d6-b96faea95785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b5d95f-1ac6-45a9-8e65-be8eb390635e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "136cf873-b7c3-457d-a564-ac30bf93a681",
   "metadata": {},
   "source": [
    "## tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "247dda27-0b13-4cd8-bc2e-b155be2e7d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train['tags']  = df_train.tags.apply(lambda x: literal_eval(x))\n",
    "#df_test['tags']   = df_test.tags.apply( lambda x: literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1669271c-d557-4f24-9c43-480d0dfaa233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tags_features(inp_df):\n",
    "    \n",
    "    inp_df[\"tags_int\"] = inp_df.tags.astype('category')\n",
    "    inp_df[\"tags_int\"] = inp_df.tags_int.cat.codes\n",
    "    inp_df[\"tags_int\"] = inp_df.tags_int.astype('int')\n",
    "    \n",
    "    \n",
    "    inp_df['tags'] = inp_df.tags.apply(lambda x: literal_eval(x))\n",
    "    inp_df['ntags'] = inp_df.tags.apply(lambda x: len(x))\n",
    "    \n",
    "    if 'tags_int' not in clmns['tags']['num']:\n",
    "        clmns['tags']['num'].extend(['ntags', 'tags_int'])\n",
    "        \n",
    "    return inp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a824905a-3096-4810-8196-48a1cc36d830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before  (6981, 502) (3000, 500)\n",
      "after   (6981, 504) (3000, 502)\n"
     ]
    }
   ],
   "source": [
    "print('before ', df_train.shape, df_test.shape, )\n",
    "df_train = add_tags_features(df_train)\n",
    "df_test = add_tags_features(df_test)\n",
    "print('after  ', df_train.shape, df_test.shape, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00632fb6-9f9e-421d-a2aa-e75c9b17bc7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "115311d9-2d0b-4770-8dcf-02909a1a8099",
   "metadata": {},
   "source": [
    "all_tags = set()\n",
    "for el in df_train.tags.values:\n",
    "    if len (el) == 0:\n",
    "        continue\n",
    "    if len(el) == 1:\n",
    "        all_tags.add(el[0])\n",
    "        continue\n",
    "        \n",
    "    for tag in el:\n",
    "        all_tags.add(tag)\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "id": "41f6d5b2-f1e6-49f8-9909-693da4fe8b8f",
   "metadata": {},
   "source": [
    "if not os.path.exists(os.path.join(DIR_DATA, 'df_tags.csv')):\n",
    "    tag_columns = ['tag', 'm_d', 'tag_size', 'v_tag_min', 'v_tag_max', 'v_tag_mean', 'v_tag_std', 'd_tag_min',\n",
    "                  'd_tag_max', 'd_tag_mean', 'd_tag_std', 'f_tag_min', 'f_tag_max', 'f_tag_mean', 'f_tag_std',\n",
    "                 ]\n",
    "\n",
    "    tag_group_columns = ['tag_size', \n",
    "                            'v_tag_min', 'v_tag_max', 'v_tag_mean', 'v_tag_std',\n",
    "                            'tag_size2',\n",
    "                            'd_tag_min', 'd_tag_max', 'd_tag_mean', 'd_tag_std',\n",
    "                            'tag_size3',\n",
    "                            'f_tag_min', 'f_tag_max', 'f_tag_mean', 'f_tag_std',\n",
    "                       ]\n",
    "    \n",
    "    df_tags = pd.DataFrame(columns = tag_columns)\n",
    "    for el in tqdm(all_tags):\n",
    "        # собираем статистики текущего tag\n",
    "        df_train['cur_tag'] = df_train.tags.apply(lambda x: el if el in x else 0)\n",
    "\n",
    "        tmp = df_train.groupby(['cur_tag', 'm_d'])[['views', 'depth', 'full_reads_percent']].agg(['size', 'min', 'max', 'mean', 'std'])\n",
    "        tmp.columns = tag_group_columns\n",
    "        tmp.reset_index(inplace = True)\n",
    "        tmp.drop(['tag_size2', 'tag_size3'], axis = 1, inplace = True)\n",
    "\n",
    "        tmp = tmp[tmp.cur_tag != 0 ]\n",
    "        df_tags = pd.concat([df_tags, tmp], ignore_index = True, axis = 0)\n",
    "        df_tags['tag'] = df_tags.cur_tag\n",
    "        #df_tags.drop(['cur_tag'], inplace = True, axis = 1)\n",
    "        \n",
    "    df_tags.to_csv(os.path.join(DIR_DATA, 'df_tags.csv'), index = False) \n",
    "else:\n",
    "    df_tags =  pd.read_csv(os.path.join(DIR_DATA, 'df_tags.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daadd0c9-04d0-4058-ad9e-011bb961ff03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5a4271-0d07-4c19-989a-1c7c84604b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3e3c3862-e2cf-4677-8dfe-6179ee7b4080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa2cf6f-df21-4dae-9f96-60346e599e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef5b993-9298-4e29-846f-a3cfaa657cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680e3e5d-6474-439e-9182-2e98802cbd4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf2a739-cf4c-441b-b8a7-222603b46383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c75c4b-bebb-416b-b89f-f36d5dbc3061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5856f47d-8204-4e17-938d-ffbe047c6faf",
   "metadata": {},
   "source": [
    "# text_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "68bd3a11-3afb-4878-b12a-b9dbef66a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_text_len_features(inp_df):\n",
    "    \n",
    "    \n",
    "    inp_df[\"text_len_2\"] = inp_df.text_len.apply(lambda x: 1 / (x+1)**2)\n",
    "    inp_df[\"text_len_3\"] = inp_df.text_len.apply(lambda x: np.sqrt(x))\n",
    "    \n",
    "    if 'text_len_2' not in clmns['document_id']['num']:\n",
    "        clmns['document_id']['num'].extend(['text_len_2', 'text_len_3'])\n",
    "    \n",
    "    return inp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e8e027ca-f5c8-45fd-bb9d-b7a6f6a25c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before  (6981, 504) (3000, 502)\n",
      "after   (6981, 506) (3000, 504)\n"
     ]
    }
   ],
   "source": [
    "print('before ', df_train.shape, df_test.shape, )\n",
    "df_train = add_text_len_features(df_train)\n",
    "df_test = add_text_len_features(df_test)\n",
    "print('after  ', df_train.shape, df_test.shape, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5773dfd3-0e50-442d-b8fe-9ba3c2feb11e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28afb61-cd82-4b66-a070-f691a01a582b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b426d418-dd29-446a-9519-00913648ab6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0cb300-dcc5-4616-9c76-186ee76dbda8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c520ad8a-370b-4fde-ab14-4dc28bd027e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01727832-2dcf-48bb-b4b4-cda9de5ecc45",
   "metadata": {},
   "source": [
    "## Предобработка признаков в датасетах"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c494b7f2-2869-42e2-b62b-966e11cef671",
   "metadata": {},
   "source": [
    "выделяем числовые признаки для нормализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4764ee43-5a01-4043-bc3c-88ccd0557aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ph_report', 'ph_gallery', 'tv_prog', 'online', 'video', 'infogr', 'interview']\n",
      "['hour', 'dow', 'day', 'mounth', 'hour_peak', 'holiday', 'day_before_holiday', 'day_after_holiday', 'distrib_brdr']\n"
     ]
    }
   ],
   "source": [
    "cat_cols = []\n",
    "num_cols = []\n",
    "\n",
    "for el in clmns.keys():\n",
    "    cat_cols.extend(clmns[el]['cat'])\n",
    "    num_cols.extend(clmns[el]['num'])\n",
    "    if len(clmns[el]['both']) != 0:\n",
    "        print(clmns[el]['both'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5c4279be-9335-43a6-bfc0-a717bb128bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols.extend(['hour', 'mounth', 'dow', ])\n",
    "cat_cols.extend([ 'ph_report', 'ph_gallery', 'tv_prog', 'online', 'video', 'infogr',\n",
    "                  'holiday', 'day_before_holiday', 'day_after_holiday', 'distrib_brdr',\n",
    "                  #'spec_event_1'\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c025ec2-f938-4f76-ac33-65390874e458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baab023-5c82-4d36-b8d5-bc62ff386e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68737346-5571-4e3c-a232-774fd5fd5134",
   "metadata": {},
   "source": [
    "# Полипризнаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ce3032b7-c6c9-4633-9178-6ad8e4309778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_cols = ['Nauthors', 'ctr', 'text_len', 'hour', 'day', 'mounth', 'dow', 'nimgs', 'category_int']\n",
    "len(poly_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "82e1fcd9-66b5-4f83-92fa-e4873b3acfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#poly2 = preprocessing.PolynomialFeatures(degree = 2, include_bias = False)\n",
    "#oly2.fit(df_train[poly_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "35442111-8b1c-455b-86ed-4ac93b6110ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#poly3 = preprocessing.PolynomialFeatures(degree = 3, include_bias = False)\n",
    "#poly3.fit(df_train[poly_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67545a3-42e9-4adb-9cfd-4e318746321b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d1624bc4-0134-4110-b768-07840560db6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addd_poly(inp_df, inp_poly):\n",
    "    \n",
    "    inp_cols = inp_df.columns\n",
    "    \n",
    "    tmp = inp_poly.transform(inp_df[poly_cols])\n",
    "    tmp = pd.DataFrame(tmp, columns = inp_poly.get_feature_names(poly_cols))\n",
    "    \n",
    "    inp_df = pd.concat([inp_df, \n",
    "                        tmp.iloc[:, len(poly_cols):]\n",
    "                       ], ignore_index = True, axis = 1)\n",
    "    new_cols = list(inp_cols) + list(inp_poly.get_feature_names(poly_cols)[len(poly_cols):])\n",
    "    \n",
    "    inp_df.columns = new_cols\n",
    "         \n",
    "    if inp_poly.get_feature_names(poly_cols)[-1] not in clmns['poly']['num']:\n",
    "        clmns['poly']['num'].extend(inp_poly.get_feature_names(poly_cols)[len(poly_cols):])\n",
    "        \n",
    "        \n",
    "    return inp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9b662935-bad2-4fad-9bb1-770d9e679658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('before ', df_train.shape, df_test.shape)\n",
    "#df_train = addd_poly(df_train, poly2) #poly3\n",
    "#df_test  = addd_poly(df_test,  poly2) #poly3\n",
    "#print('after  ', df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befaee49-fb26-4ae2-848a-af1a9b37eac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "303adff7-f061-427e-b748-0042c5d22b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_cols.extend(clmns['poly']['num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2fd2a2-eb90-4cac-9f26-60f7ed373259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9bd615ea-f203-4a6f-a81c-46cd2abac416",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(os.path.join( DIR_DATA, 'train_upd_no_norm.csv'), index = False)\n",
    "df_test.to_csv(os.path.join( DIR_DATA,  'test_upd_no_norm.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fc8c96-c08b-4485-bbe6-d5b888bec460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db340078-8e72-4cce-a1e9-7acfae390f0a",
   "metadata": {},
   "source": [
    "нормализуем"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9194d131-c3dd-4800-ad8a-cc88b6ba4826",
   "metadata": {},
   "source": [
    "#scaler = preprocessing.MinMaxScaler()   #Transform features by scaling each feature to a given range.\n",
    "#scaler = preprocessing.Normalizer()     #Normalize samples individually to unit norm.\n",
    "scaler = preprocessing.StandardScaler()  #Standardize features by removing the mean and scaling to unit variance.\n",
    "\n",
    "scaler.fit(df_train[num_cols])\n",
    "\n",
    "df_train[num_cols] = scaler.transform(df_train[num_cols])\n",
    "df_test[num_cols]  = scaler.transform(df_test[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e5d8389a-84e9-40df-907d-6dd5f64deaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_start = preprocessing.StandardScaler()  #Standardize features by removing the mean and scaling to unit variance.\n",
    "scaler_end = preprocessing.StandardScaler()  #Standardize features by removing the mean and scaling to unit variance.\n",
    "\n",
    "scaler_start.fit(df_train[df_train.distrib_brdr == 1][num_cols])\n",
    "scaler_end.fit(df_train[df_train.distrib_brdr == 0][num_cols])\n",
    "\n",
    "df_train.loc[df_train.query('distrib_brdr == 1').index, num_cols] = scaler_start.transform(df_train[df_train.distrib_brdr == 1][num_cols])\n",
    "df_test.loc[df_test.query('distrib_brdr == 1').index, num_cols]  = scaler_start.transform(df_test[df_test.distrib_brdr == 1][num_cols])\n",
    "\n",
    "df_train.loc[df_train.query('distrib_brdr == 0').index, num_cols] = scaler_end.transform(df_train[df_train.distrib_brdr == 0][num_cols])\n",
    "df_test.loc[df_test.query('distrib_brdr == 0').index, num_cols]  = scaler_end.transform(df_test[df_test.distrib_brdr == 0][num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766a92d0-2c5b-4850-90de-3c7d60919348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "39ffdd7b-0473-40a1-9313-efe948ef8de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# определяем CTR_UKR спецстатей по украине после нормализации\n",
    "#for el in doc_id_ukr:\n",
    "#    print(df_test[df_test.document_id == el].ctr.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdddfe3-d27a-412e-b896-ff1a887ef04a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04766e94-98c6-4255-9a53-bc5aa46d47b1",
   "metadata": {},
   "source": [
    "Добавляем эмбединги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b7a79318-af7f-4fa8-bbe5-35ec2fd9aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sberbank-ai/sbert_large_mt_nlu_ru       1024  1.71Gb\n",
    "# DeepPavlov/rubert-base-cased-sentence   768   0.7Gb\n",
    "# DeepPavlov/rubert-base-cased-conversational  768\n",
    "# DeepPavlov/rubert-base-cased            768\n",
    "# sberbank-ai/sbert_large_nlu_ru          1024  1.71Gb\n",
    "\n",
    "#MODEL_FOLDER = 'rubert-base-cased-sentence'\n",
    "MODEL_FOLDER = 'sbert_large_mt_nlu_ru'\n",
    "MAX_LENGTH = 24\n",
    "PCA_COMPONENTS = 64"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3f2a3ac-36cc-4d92-be2d-8eecbbcb2afa",
   "metadata": {},
   "source": [
    "def add_ttle_embeding(inp_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    pass    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bf4a10d3-0920-487a-adbd-8311ee748a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6981, 570), (7000, 65))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_train = pd.read_csv(os.path.join(DIR_DATA, f'ttl_cln_emb_train_{MODEL_FOLDER}_{MAX_LENGTH}_pca{PCA_COMPONENTS}.csv'))\n",
    "#emb_train.drop(['document_id', 'title'], axis = 1 , inplace = True)\n",
    "emb_train.drop(['true_title'], axis = 1 , inplace = True)\n",
    "\n",
    "df_train = df_train.merge(emb_train, on = 'document_id', validate = 'one_to_one')\n",
    "df_train.shape, emb_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c768dd96-cfc7-4c89-903d-b04046d1e1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 568), (3000, 65))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_test = pd.read_csv(os.path.join(DIR_DATA, f'ttl_cln_emb_test_{MODEL_FOLDER}_{MAX_LENGTH}_pca{PCA_COMPONENTS}.csv'))\n",
    "#emb_test.drop(['document_id', 'title'], axis = 1 , inplace = True)\n",
    "emb_test.drop(['true_title'], axis = 1 , inplace = True)\n",
    "\n",
    "df_test = df_test.merge(emb_test, on = 'document_id', validate = 'one_to_one')\n",
    "df_test.shape, emb_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0a3fb1e7-1b33-4f13-bbef-8707b6af2bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = num_cols + list(emb_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "21e69b4c-2957-415b-bc4e-fa5f7f703f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'document_id' in num_cols:\n",
    "    num_cols.remove('document_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "26adfc18-7c1a-485c-a2da-f2e71eb4a264",
   "metadata": {},
   "outputs": [],
   "source": [
    "clmns['title']['num'].extend(emb_train.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9393c3cb-f63e-4c8b-8713-69695581e3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac27d63-a4ac-4c4d-bb76-61db444d9470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "252d3409-7429-4fdf-9e79-43ba84b0d727",
   "metadata": {},
   "source": [
    "## save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "119148f6-87af-4047-8a0d-ae74efa8b7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 568), (3000, 568))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "be0dbd1c-5b07-43fe-baf7-e4d7bcfaef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(os.path.join( DIR_DATA, 'train_upd.csv'))\n",
    "df_test.to_csv(os.path.join( DIR_DATA,  'test_upd.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "db13180c-5188-4dfa-bbaa-a42ed582e61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DIR_DATA, 'clmns.pkl'), 'wb') as pickle_file:\n",
    "    pkl.dump(clmns, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac1bb39-d9df-49f9-9ef0-4f17228443a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a8439a85-2a07-4fbb-a532-ccc88c094303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook Runtime: 0.86 Minutes\n"
     ]
    }
   ],
   "source": [
    "print(\"Notebook Runtime: %0.2f Minutes\"%((time.time() - notebookstart)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5320bc25-347c-49a7-88b9-2419a8d5de80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "747baa53-ef7f-4074-918b-7911d78bac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clmns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "74ee0eaa-9dba-41cc-b612-d16298e8e3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4318445d-a44c-42e8-b13b-81c0572b352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1129ad-1f34-48b8-803b-ff09048d5541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c7349e-cb4f-4e73-85ac-0128e28b561e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b8a4be-6750-417f-8a12-bc0311f340ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
