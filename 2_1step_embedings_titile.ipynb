{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96329acc-35c5-4cf6-8b5c-9f4add52afb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8692c7a-3d02-4c33-b389-946483556874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2022-09-12T00:58:04.900101+03:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.12\n",
      "IPython version      : 8.2.0\n",
      "\n",
      "Compiler    : MSC v.1916 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 158 Stepping 9, GenuineIntel\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91621940-df8c-49a6-8776-f053f6a96183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "notebookstart = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e810963-65eb-4b4d-bb7a-a7c0e33d2151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f465c5ae-4d5e-4942-b7e8-8894208c0a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11129389-5cb8-48ad-9fc2-91a9764d02b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64cb53ee-4b29-47a3-add2-b0d90dd27bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from functools import partial\n",
    "#from embtitile import embtitile as et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25bba1ca-012d-4ef5-997f-88d594ffb4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ray\n",
    "#ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ce9c75-a25e-4ec7-9ef6-28fa4c6c5e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8298844-a87b-4a5b-aaf5-b5a8dc167d57",
   "metadata": {},
   "source": [
    "Переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "652c4abd-e819-4ff9-add6-7f2b0093f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_DATA  = os.path.join(os.getcwd(), 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643e4489-dd22-4424-91dc-dd64747a84fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57dbe8b9-7199-412a-a83d-dc4ca40b1470",
   "metadata": {},
   "source": [
    "## Загружаем и подготавливаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "668e7928-c2a2-4ae7-81dd-5030382018b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'_extended' после парсинга данных с РБК и извлечения данных из спарсенных страниц\n",
    "df_train = pd.read_csv(os.path.join(DIR_DATA, 'train_extended.csv'))\n",
    "df_test  = pd.read_csv(os.path.join(DIR_DATA, 'test_extended.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fac10c41-28fa-4d1b-bfce-3b89dd0dcffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#имя            размерность выходного вектора   вес модели\n",
    "# sberbank-ai/sbert_large_mt_nlu_ru       1024  1.71Gb\n",
    "# DeepPavlov/rubert-base-cased-sentence   768   0.7Gb\n",
    "# DeepPavlov/rubert-base-cased-conversational  768\n",
    "# DeepPavlov/rubert-base-cased            768\n",
    "# sberbank-ai/sbert_large_nlu_ru          1024  1.71Gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e47016d-d69f-4f86-a3a4-dae2ffbd0f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6206673f-b9cf-4a1e-93aa-0608a203621c",
   "metadata": {},
   "source": [
    "## Загружаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa12e345-be93-4ddf-9dea-03b3103f2828",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitleEmb:\n",
    "    def __init__(self, inp_model_name: str, inp_model_folder: str, inp_max_length: int, inp_npca_components: int) -> None:\n",
    "        \"\"\"\n",
    "        Инициализация класса\n",
    "        args:\n",
    "            inp_model_name   - название модели на huggingface\n",
    "            inp_model_folder - папка модели\n",
    "            inp_max_length   - максимальная длинна текста (заголовка) для обработки\n",
    "            inp_npca_components - длина эмбеддинга после PCA (кол-во компонент)\n",
    "        return:\n",
    "        \"\"\"\n",
    "        self.pre_trained_model_name   = inp_model_name\n",
    "        self.pre_trained_model_folder = inp_model_folder\n",
    "        self.max_length = inp_max_length\n",
    "        self.npca_components = inp_npca_components\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.pre_trained_model_name)\n",
    "        self.model = AutoModel.from_pretrained(self.pre_trained_model_name)     \n",
    "        _ = self.model.cpu()\n",
    "\n",
    "        self.pca = PCA(n_components = self.npca_components)\n",
    "        \n",
    "\n",
    "    #Mean Pooling - Take attention mask into account for correct averaging    \n",
    "    def mean_pooling(self, model_output, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Усреднение с учетом маски (более точное)\n",
    "        args:\n",
    "            model_output - предсказанный эмбеддинг\n",
    "            attention_mask - масска внимания для уточнения пулинга\n",
    "        return:\n",
    "            усредненный эмбеддинг с учетом маски внимания\n",
    "        \"\"\"\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "        return sum_embeddings / sum_mask\n",
    "    \n",
    "    \n",
    "    \n",
    "    def ttl_to_emb(self, inp_text: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Преобразование заголовка к эмбеддингу\n",
    "        args:\n",
    "            inp_text - текст (заголовок), для преобразования в эмбеддинги\n",
    "        return:\n",
    "            np.ndarray - эмбеддинг входного текста\n",
    "        \"\"\"\n",
    "        encoded_input = self.tokenizer(inp_text, padding = True, truncation = True, max_length = self.max_length, return_tensors = 'pt')\n",
    "\n",
    "        #Compute token embeddings\n",
    "        with torch.no_grad():\n",
    "            model_output = self.model(**encoded_input)\n",
    "\n",
    "        sentence_embeddings = self.mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "        #print('model_output', type(model_output))\n",
    "        #print('encoded_input', type(encoded_input['attention_mask']))\n",
    "        #print('sentence_embeddings', type(sentence_embeddings))\n",
    "        return sentence_embeddings[0].cpu().detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "    def make_title_emb_features(self, inp_df: pd.DataFrame, train_pca: bool) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Добавление эмбеддингов заголовков к заданному DataFram'у\n",
    "        args:\n",
    "            inp_df - входной pd.DataFrame для преобразования\n",
    "            train_pca - необходимо ли обучать PCA или только преобразовывать\n",
    "        return:\n",
    "            pd.DataFrame - исходный DataFrame расширенный эмбеддингами заголовков\n",
    "        \"\"\"\n",
    "        inp_df = inp_df[['document_id', 'true_title']]\n",
    "        #inp_df.loc[:, 'ttl_emb'] = inp_df.true_title.progress_apply(lambda x: self.ttl_to_emb(x))\n",
    "        inp_df['ttl_emb'] = inp_df.true_title.progress_apply(lambda x: self.ttl_to_emb(x))\n",
    "        \n",
    "        if train_pca:\n",
    "            self.pca.fit(inp_df.ttl_emb.to_list())\n",
    "            print('fitting pca')\n",
    "            \n",
    "        col_names = [f'tt_emb{idx}' for idx in range(self.npca_components)]\n",
    "        emb_train = pd.DataFrame(self.pca.transform(inp_df.ttl_emb.to_list()), columns = col_names)\n",
    "        \n",
    "        inp_df = pd.concat([inp_df, emb_train], axis=1)\n",
    "        inp_df.drop('ttl_emb', axis = 1, inplace = True)\n",
    "    \n",
    "        return inp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b7e6e5b-4596-4951-8329-d9dd407d6abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRE_TRAINED_MODEL_NAME = 'blanchefort/rubert-base-cased-sentiment-rurewiews'\n",
    "#MODEL_FOLDER = 'ru-blanchefort-rurewiews2'\n",
    "\n",
    "#'DeepPavlov/rubert-base-cased-sentence'\n",
    "#'sberbank-ai/sbert_large_mt_nlu_ru'\n",
    "\n",
    "#PRE_TRAINED_MODEL_NAME = 'DeepPavlov/rubert-base-cased-sentence'\n",
    "#MODEL_FOLDER = 'rubert-base-cased-sentence'\n",
    "\n",
    "PRE_TRAINED_MODEL_NAME = 'sberbank-ai/sbert_large_mt_nlu_ru'\n",
    "MODEL_FOLDER = 'sbert_large_mt_nlu_ru'\n",
    "\n",
    "\n",
    "MAX_LENGTH = 24\n",
    "\n",
    "PCA_COMPONENTS = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20cab019-377b-446a-8c50-136c8edd7918",
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TitleEmb(PRE_TRAINED_MODEL_NAME, MODEL_FOLDER, MAX_LENGTH, PCA_COMPONENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d4b12f3-3d79-472f-8081-f27619af7804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before  (7000, 17) (3000, 14)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe2461b24e4c40c6814c26a0639056ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\_v010ch_\\AppData\\Local\\Temp\\ipykernel_15224\\2131857874.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inp_df['ttl_emb'] = inp_df.true_title.progress_apply(lambda x: self.ttl_to_emb(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting pca\n",
      "after   (7000, 66) (3000, 14)\n"
     ]
    }
   ],
   "source": [
    "print('before ', df_train.shape, df_test.shape)\n",
    "df_train = te.make_title_emb_features(df_train, True)\n",
    "df_test  = te.make_title_emb_features(df_test,  False)\n",
    "print('after  ', df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e70a3714-4687-4336-b140-4e900e2c6df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train2 = te.make_title_emb_features(df_train[:100], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd1d4bf-6cd5-4f26-b2e5-16c5b2cb7ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e9ed7a-c969-4960-afca-144bee6b028f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cf1d60-a2aa-457a-9f74-df30584db13f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae9fabc6-2744-4529-a285-3f349d50be6e",
   "metadata": {},
   "source": [
    "Сохраняем только эмбеддинги, без остальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e579438f-3ab3-4e11-ad87-3d43c57dab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(os.path.join(DIR_DATA, f'ttl_cln_emb_train_{MODEL_FOLDER}_{MAX_LENGTH}_pca{PCA_COMPONENTS}.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66514498-9f86-40f8-82fb-8b2c4a859178",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(os.path.join(DIR_DATA, f'ttl_cln_emb_test_{MODEL_FOLDER}_{MAX_LENGTH}_pca{PCA_COMPONENTS}.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f7ae2f-e088-4250-bb81-f5ae0cee3665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d2863e3-cf41-4843-a6a4-a7783cddb490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75daa81e-4694-4105-aeb2-5dc1c30decbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook Runtime: 25.77 Minutes\n"
     ]
    }
   ],
   "source": [
    "print(\"Notebook Runtime: %0.2f Minutes\"%((time.time() - notebookstart)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f52f0b5-f43f-4bd6-856a-e9be15b9e199",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
