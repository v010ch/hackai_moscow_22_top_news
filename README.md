# hackai_moscow_top_news
predict the main themes for different target audiences. https://hacks-ai.ru/championships/758453






Оглавление:
- Структура директорий проекта
- Описание
- Выполнение




СТРУКТУРА ДИРЕКТОРИЙ ПРОЕКТА

═╦══data═╦═train.csv
 ║       ║
 ║       ╠═test.csv
 ║       ║
 ║       ╚═pages/*.html
 ║
 ╠═models═
 ║
 ╚═subm══╦═
         ║
         ╚═partial═
 
 в data находятся изначальные train и test.csv.
 в нее же будут добавляться различные промежуточные файлы,
 исользуемые при построении признаков и моделей.
 
 в pages хранятся все загруженные статьи.
 их можно загрузить самостоятельно, откомментировав блоки в 2step_rbk_parse.ipynb, 
 начинающиеся с 'load_number = 0'
 однако это занимает долгое время (с учетом защиты от блокировки),
 так что лучше все html загрузить сразу архивом с gdrive
 https://drive.google.com/file/d/1buUc2sJdVigoHu2QrtADblHui2CF35f1/view?usp=sharing
  
 в models сохраняются все обученные модели.
 
 в subm сохраняются все предсказания.
 
 в partial сохраняются предсказания, необходимые для обучения ансамбля 
 (не обучается в итоге)




 ОПИСАНИЕ
 
 
 
 ВЫПОЛНЕНИЕ
  
 
 В первую очередь хочу обратить внимание, что проект выполнялся на старых версиях библиотек:
 sklearn          : 0.24.2
 numpy            : 1.20.3
 pandas           : 0.25.3
 С последними версиями известны проблеммы совместимости в названии атрибутов.
 Ведется работа над решением данного вопроса. Пока в процессе.
  
 0. Все ячейки в файлах выполняются последовательно сверху вниз;
 1. Первым этапом идет загрузка данных. Лучше выполнить, скачав архив с gdrive 
    https://drive.google.com/file/d/1buUc2sJdVigoHu2QrtADblHui2CF35f1/view?usp=sharing
    и распаковав в ./data/pages/. 
    Однако можно и загрузить самостоятельно, откомментировав блоки, начинающиеся с 
    'load_number = 0' в файле 2step_rbk_parse.ipynb;
 2. Далее идет полное выполнение 2step_rbk_parse.ipynb. где из загруженных в п.1 файлов 
    собирается информация (длинна текста, количество изображений в статье и пр.) и сохраняется
    в расширенных файлах train_extended.csv и test_extended.csv;
 3. Затем выполняется файл 2step_embedings_titile.ipynb. в нем заголовки преобразуются в 
    эмбединги (sberbank-ai/sbert_large_mt_nlu_ru) после чего они пережимаются через pca до 
    вектора длинной 64;
 4. Выполняется файл 2step_make_feauturesюшзнти в котором происходит очистка данных,
    формируются статистики (min, max и т.д.) и ряд других признаков;
 5. Выполняется файл 3step_modeling_catboost.ipynb котором происходит обучение модели и построение предсказания. 
    Предсказание (файл сабмита) будет сохранен в директории subm;
 
